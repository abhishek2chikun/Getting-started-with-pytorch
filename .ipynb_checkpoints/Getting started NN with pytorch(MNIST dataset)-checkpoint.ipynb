{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms,datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the data\n",
    "train = datasets.MNIST('', train=True, download=False,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "test = datasets.MNIST('', train=False, download=False,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data and make the batches\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=16,shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=16,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([3, 6, 8, 4, 9, 3, 3, 4, 9, 1, 5, 4, 8, 0, 0, 2])]\n"
     ]
    }
   ],
   "source": [
    "#Let's just analyze one dataset\n",
    "for data in trainset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "#Let me extract the first 0\n",
    "x,y=data[0][13],data[1][13]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visulize \n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x.view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#it's a 0!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It'check if it is normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 28, 28])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0667, 0.6039,\n",
       "        0.9922, 0.9922, 0.7686, 0.0863, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][0][0][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1608, 0.6549,\n",
       "        0.9922, 0.9922, 0.9922, 0.9922, 0.9255, 0.6549, 0.0706, 0.1098, 0.9922,\n",
       "        0.9922, 0.0510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][0][0][15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data is already normalized i.e. in scale 0-1\n",
    "#If it is not normalized we can simpily divide by 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n",
      "0: 9.871666666666666%\n",
      "1: 11.236666666666666%\n",
      "2: 9.93%\n",
      "3: 10.218333333333334%\n",
      "4: 9.736666666666666%\n",
      "5: 9.035%\n",
      "6: 9.863333333333333%\n",
      "7: 10.441666666666666%\n",
      "8: 9.751666666666667%\n",
      "9: 9.915000000000001%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "total = 0\n",
    "counter_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n",
    "\n",
    "\n",
    "for data in trainset:\n",
    "    Xs, ys = data\n",
    "    for y in ys:\n",
    "        counter_dict[int(y)] += 1\n",
    "        total += 1\n",
    "\n",
    "print(counter_dict)\n",
    "for i in counter_dict:\n",
    "    #x.append({i: counter_dict[i]/total*100.0})\n",
    "    print(f\"{i}: {counter_dict[i]/total*100.0}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net()\n"
     ]
    }
   ],
   "source": [
    "#difine class\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "n=Net()\n",
    "print(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#initilize FC layers\n",
    "#difine class\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(28*28,128)\n",
    "        self.fc2 = nn.Linear(128,64)\n",
    "        self.fc3 = nn.Linear(64,64)\n",
    "        self.fc4 = nn.Linear(64,10)\n",
    "        \n",
    "        \n",
    "        \n",
    "n=Net()\n",
    "print(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc5): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#1.We have initilize Layer now let's write the function for feed forward\n",
    "#2.Apply activation function to the forward network\n",
    "import torch.nn.functional as F\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(28*28,128)\n",
    "        self.fc2 = nn.Linear(128,64)\n",
    "        self.fc3 = nn.Linear(64,64)\n",
    "        self.fc4 = nn.Linear(64,32)\n",
    "        self.fc5 = nn.Linear(32,10)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "            \n",
    "        return F.log_softmax(x,dim=1)       #getting probability[0.77,0.3,0.55,....]\n",
    "        \n",
    "        \n",
    "        \n",
    "NN=Net()\n",
    "print(NN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initilizing learning rate, optimizer and loss \n",
    "import torch.optim as Op\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = Op.Adam(NN.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0077, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0287, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1387, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0128, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0030, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5796, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Grab the features (X) and labels (y) from current batch\n",
    "# Zero the gradients (net.zero_grad)\n",
    "# Pass the data through the network\n",
    "# Calculate the loss\n",
    "# Adjust weights in the network with the hopes of decreasing loss\n",
    "\n",
    "\n",
    "for epoch in range(10):                           #Number of Epoch \n",
    "    for data in trainset:\n",
    "        \n",
    "        #Forward propagation\n",
    "        \n",
    "        x,y=data                                 #X and Y split\n",
    "        \n",
    "        NN.zero_grad()                           #Initilizing Gradident(Minimize the loss)\n",
    "        \n",
    "        output = NN(x.view(-1,28*28))            #Input DATA into your network\n",
    "        \n",
    "        loss= F.nll_loss(output,y)               #Calculate loss\n",
    "        \n",
    "        #Now backward propagation\n",
    "        \n",
    "        loss.backward()                          #Do Backward propagation from the loss function\n",
    "        \n",
    "        optimizer.step()                         #Update weight and bias\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9798\n"
     ]
    }
   ],
   "source": [
    "#testing accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for data in testset:\n",
    "        \n",
    "        x,y = data\n",
    "        \n",
    "        output = NN(x.view(-1,28*28))\n",
    "        \n",
    "        for idx,i in enumerate(output):\n",
    "            \n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                \n",
    "                correct+=1\n",
    "            \n",
    "            total+=1\n",
    "    print(f'Accuracy:{(correct/total)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We achieve 97% accuracy!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(y[0])\n",
    "plt.imshow(x[0].reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "#test your model\n",
    "output=NN(x[0].view(-1,28*28))         #Predict\n",
    "print(torch.argmax(output[0]))         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
